{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-XphER4SWG6"
   },
   "source": [
    "# <center> PDL Lab10 Tutorial: Multi-class Classification using MNIST dataset </center>\n",
    "\n",
    "### 205229103\n",
    "\n",
    "### Arzoo Sah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will build a Neural Network multi-class classification model using a dataset popularly known as **'MNIST'**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcWWIvw2RxlS"
   },
   "source": [
    "# Agenda\n",
    "*  About the Data\n",
    "*  Loading Libraries\n",
    "*  Loading Data\n",
    "*  Basic EDA\n",
    "*  Data Preprocessing\n",
    "*  Model Building\n",
    "  *  Simple Neural Network With No Hidden Layer\n",
    "  *  Building Model Using Hidden Layer\n",
    "*  Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3x9Y9moS5fY"
   },
   "source": [
    "## About the Data\n",
    "**MNIST (Modified National Institute of Standards and Technology database)** is a large database of 70,000 handwritten digits. \n",
    "\n",
    "It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST (National Institute of Standards and Technology).\n",
    "\n",
    "The objective here is to build a model that would recognize the correct digit that the given image is representing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8udR2dR1CAm"
   },
   "source": [
    "## Objective\n",
    "In this notebook we will classify handwritten digits using a simple neural network which has only input and output layers. We will then add a hidden layer and see how the performance of the model improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y06TLJHMU_5x"
   },
   "source": [
    "## Loading Libraries\n",
    "All Python capabilities are not loaded to our working environment by default (even if they are already installed in your system). So, we import each and every library that we want to use. Sometimes we chose alias names for our libraries for the sake of our convenience for example we **import tensorflow as tf** and similarly the other libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6IzyeUHFlId"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf                       # deep learning library\n",
    "import numpy as np  # for matrix operations\n",
    "import matplotlib.pyplot as plt               # for visualization\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ph7HLzWTFlIr"
   },
   "source": [
    "## Loading Data\n",
    "The MNIST dataset is available in the TensorFlow only. Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubTJHv0xFlIr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data    # To load the MNIST digit dataset\n",
    "\n",
    "(X_train, y_train) , (X_test, y_test) = load_data()      # Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGVmx0ra2QLt"
   },
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "m6WviKsE2Ism",
    "outputId": "83c42917-14d1-4c03-9043-aa200dc90ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  60000 images in the training dataset\n",
      "There are  10000 images in the test dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \", len(X_train), \"images in the training dataset\")     # checking total number of records / data points available in the X_train dataset\n",
    "print(\"There are \", len(X_test), \"images in the test dataset\")     # checking total number of records / data points available in the X_test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "12mEV-er2b7s",
    "outputId": "6da758cf-961b-419a-aa6b-1e10d4e35b6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of each image\n",
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hjJAlpfr296r"
   },
   "source": [
    "Each image in the dataset is of shape 28X28 numbers (i.e. pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "yZTMGFdy28lK",
    "outputId": "6cb19852-58fd-4fab-bef6-f78d7cbfa704"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look how one image looks like\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMsn02nQ3TvA"
   },
   "source": [
    "Only numbers! Can't understand what digit does it represent. \n",
    "\n",
    "There is a function in matplotlib called as 'matshow()', it helps you to display the image of the array of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "JDEEhHTt3Qsj",
    "outputId": "bf4ccd91-f52a-434e-ca93-014d5952afc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26cfbb2bdf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ovv623nJHbEm",
    "outputId": "1638635e-7c5c-4ec7-bc58-7cfbd9ca5dae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use y_train to cross check\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LgYJdJV3-DN"
   },
   "source": [
    "Now one can easily say the above number is 5. Well we want to build a model that will tell you what digit does that 28X28 array represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "ug3Tv0zpi5A0",
    "outputId": "7670c596-25d3-49e2-9d02-e2689d8039fd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code to view the images\n",
    "num_rows, num_cols = 2, 5\n",
    "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),gridspec_kw={'wspace':0.03, 'hspace':0.01},squeeze=True)\n",
    "\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "        image_index = r * 10 + c\n",
    "        ax[r,c].axis(\"off\")\n",
    "        ax[r,c].imshow( X_train[image_index], cmap='gray')\n",
    "        ax[r,c].set_title('No. %d' % y_train[image_index])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SR7nFyVY7UPU"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tDX1gHtS44Y0"
   },
   "source": [
    "Let's normalize our data (i.e. both X_train and X_test). Normalization is a process that changes the range of pixel intensity values to the range 0 to 1.\n",
    "\n",
    "But why to normalize?\n",
    "\n",
    "The motivation to normalize is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction and reduce the data redundancy. Also, normalizing the data can help you improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TYSYGzgr4fuG",
    "outputId": "4c635f0b-c28c-483a-f328-8f5b00a33404"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255        #The pixel value lie in the range 0 - 255 representing the RGB (Red Green Blue) value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHPqEcJT6xIx"
   },
   "source": [
    "Now if you look at the data, each pixel value should be in range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SGxTk0bM6lA4",
    "outputId": "6014b3a9-3129-4ed1-98d7-c224d3edb3b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwgjOLnw7Rl1"
   },
   "source": [
    "**Flatten the Data**\n",
    "\n",
    "We simply convert a 2 dimensional data (i.e. one image data) to 1 dimensional.\n",
    "\n",
    "Why to flatten data?\n",
    "\n",
    "Before understanding why let's check the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Krewjr8d60yL",
    "outputId": "5d208958-f82c-4539-f1a1-a44934af4681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCghTfZt89QE"
   },
   "source": [
    "The data is 3 dimensional. The first value i.e. 60000 is nothing but the number of records or images in this case. The second and third dimension represent each individual image i.e. each image is of shape 28X28. \n",
    "\n",
    "Most of the the supervised learning algorithms that execute classification and regression tasks, as well as some deep learning models built for this purposes, are fed with two-dimensional data. Since we have our data as three-dimensional, we will need to flatten our data to make it two-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTxiNjn287uw"
   },
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)    # converting our 2D array representin an image to one dimensional\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHF9he2FCMNG"
   },
   "source": [
    "Now if you check the shape of our data, it should be 2 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MGA8LsPECJ9O",
    "outputId": "37048bae-a598-4932-fe89-939225bf3738"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2k1BV6lDmYC-"
   },
   "source": [
    "**A sample example showing the conversion of 3D data to 2D**\n",
    "![3Dto2D](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/3D+to++2D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rQqtuN5CY76"
   },
   "source": [
    "## Building Models\n",
    "### Very simple neural network with no hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GO6UMj04EI19"
   },
   "source": [
    "![simple neural network](https://dphi-courses.s3.ap-south-1.amazonaws.com/Deep+Learning+Bootcamp/mnist1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMJrUsyqFehV"
   },
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTFzdn5MCTeQ"
   },
   "outputs": [],
   "source": [
    "# Defining the Model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(784,), activation='sigmoid'))     # The input shape is 784. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "rEJSaVUlNlUM",
    "outputId": "f75f53b7-5ff0-4fd9-9495-3380531e3526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGGoOmoVxr57"
   },
   "source": [
    "Generally for multi-class classification problem, it is suggested to use softmax. Later you can also try using both and keep the one which gives better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ns3xpXRxFhV6"
   },
   "source": [
    "**Compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w333bVueFdTZ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFx4eplPGds9"
   },
   "source": [
    "*  **adam** is an optimization algorithm which is faster than Stochastic Gradient Descent. If you remember from the learning material of Day 4 (i.e. working of neural networks), we know that Stochastic Gradient Descent (SGD in short) is just a type of Gradient Descent algorithm.\n",
    "\n",
    "*  **sparse_categorical_crossentropy** is a loss function similar to **binary_crossentropy** (discussed in Binary Classification Notebook), the only difference is that if the target variable is binary we use binary_crossentropy but if your target values are normal integers more then two, use sparse categorical crossentropy. Why not use **categorical_crossentropy**? You may ask. Well, [this article](https://jovianlin.io/cat-crossentropy-vs-sparse-cat-crossentropy/) will help you understand it.\n",
    "\n",
    "*  The metrics used to evaluate the model is **accuracy**. Accuracy calculates how often the predictions calculated by the model are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeSNBYcYJKNp"
   },
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "pEhPuikwGaQg",
    "outputId": "d4cecd6f-f59a-49f7-e312-c3480312210a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 829us/step - loss: 0.4710 - accuracy: 0.87670s - loss: 0.4789 - accuracy: 0.\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 739us/step - loss: 0.3042 - accuracy: 0.9157\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 882us/step - loss: 0.2832 - accuracy: 0.9206\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 945us/step - loss: 0.2735 - accuracy: 0.9228\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 746us/step - loss: 0.2666 - accuracy: 0.9252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26cfbd55ee0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmIv3thYJYAD"
   },
   "source": [
    "You can play with different number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2LDdci5JdfE"
   },
   "source": [
    "**Evaluate the model on unseen data (i.e. X_test_flattened)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "onu3n0QzJO1K",
    "outputId": "9582bdfe-bd69-4723-c972-e8b2c171f20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 753us/step - loss: 0.2651 - accuracy: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2651002109050751, 0.9259999990463257]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WT3uMdwaJuO9"
   },
   "source": [
    "The performance of the model on very simple model with no hidden layer is 92.6 %. Not Bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Dmd6wUDJ8wU"
   },
   "source": [
    "**predict for the X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "cSPYvO3qJsmq",
    "outputId": "0702c476-42ee-4ff7-e787-7db10d2e4b12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.7463313e-01, 4.4026375e-03, 9.9942887e-01, 4.7130504e-01,\n",
       "       9.8689845e-10, 8.3073413e-01, 9.2270863e-01, 1.6322592e-12,\n",
       "       2.4616641e-01, 2.1485571e-09], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_flattened)\n",
    "y_predicted[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQ6HhcLrKFfb"
   },
   "source": [
    "The above numbers are the probabilities values for different digits. The maximum probability will confirm what is the predicted digit for first image in X_test.\n",
    "\n",
    "The value at the 0th index in above array of numbers is saying the probability of the digit being 0. \n",
    "\n",
    "**Generalize:** The value at the nth index in above array of numbers is saying the probability of the digit being n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWeHXcDmKudF"
   },
   "source": [
    "**np.argmax finds a maximum element from an array and returns the index of it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QZ95EnDgKEnK",
    "outputId": "094d751b-e943-4639-d0e9-0bde2da287bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predicted[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYsBH4_VKy7z"
   },
   "source": [
    "The predicted digit is 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3LlzcSXLbw6"
   },
   "source": [
    "Let's see the original digit at first index in X_test. Can see this using matshow() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pbaI7nX6KyIc",
    "outputId": "5a91519b-7893-45a6-d049-0b758595d342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26cfa52b790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qym97msLLr9A"
   },
   "source": [
    "Hence the prediction is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Now use softmax activation function to create the model, compile, predict and check your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(10, input_shape=(784,), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 830us/step - loss: 0.4656 - accuracy: 0.8793\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 808us/step - loss: 0.3034 - accuracy: 0.9154\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.2834 - accuracy: 0.9208\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 859us/step - loss: 0.2729 - accuracy: 0.9238\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.2662 - accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ca5bc46d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 710us/step - loss: 0.2666 - accuracy: 0.9256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26663264632225037, 0.925599992275238]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_flattened)\n",
    "np.argmax(y_predicted[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26ca8aaf5b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOWUlEQVR4nO3dbYwd5XnG8etivTbBvNQOsHFcKJRCRRoVO9o4KUEtEYESVAnzhWJVwVGjGFRoQIrUUlQFIjUSioIhqVQiu6AYhRChAsVSnTaOiwqU1sJ2HTA2b0lMwfgFahUbqhi/3P2w43aB3efs7pxzZpb7/5OsPWfuOTO3H6+vnTnz7BxHhADkdUzTDQBoFiEAJEcIAMkRAkByhACQHCEAJNdICNi+1Pbztl+yfVMTPZTY3m77GdubbW9oQT/32N5je8uoZXNtr7X9YvV1Tsv6u9X2jmoMN9u+rMH+TrP9qO2ttp+1fUO1vBVjWOivL2Pofs8TsD0g6QVJF0t6VdJTkpZExNa+NlJge7uk4Yh4o+leJMn270p6S9K9EfHxatk3Je2NiNuqIJ0TEX/eov5ulfRWRHyriZ5Gsz1P0ryI2GT7BEkbJS2W9EW1YAwL/V2pPoxhE0cCiyS9FBE/j4h3JP1Q0uUN9DFtRMRjkva+Z/HlklZVj1dp5JumEeP01xoRsTMiNlWP90vaJmm+WjKGhf76ookQmC/plVHPX1Uf/8ITFJJ+bHuj7WVNNzOOoYjYWT3eJWmoyWbGcb3tp6vThcZOV0azfYakhZLWq4Vj+J7+pD6MIW8Mju2CiPiEpM9Luq463G2tGDmna9v877sknSVpgaSdkm5vtBtJto+X9KCkGyNi3+haG8ZwjP76MoZNhMAOSaeNev6r1bLWiIgd1dc9kh7WyClM2+yuziWPnlPuabifd4mI3RFxOCKOSFqphsfQ9qBG/oPdFxEPVYtbM4Zj9devMWwiBJ6SdLbtM23PlHSVpNUN9DEm27OrN2dke7akSyRtKb+qEaslLa0eL5X0SIO9vM/R/1yVK9TgGNq2pLslbYuI5aNKrRjD8frr1xj2/eqAJFWXOu6UNCDpnoj4Rt+bGIftX9fIT39JmiHpB033Z/t+SRdKOlnSbkm3SPp7SQ9IOl3Sy5KujIhG3pwbp78LNXIYG5K2S7pm1Pl3v/u7QNLjkp6RdKRafLNGzrsbH8NCf0vUhzFsJAQAtAdvDALJEQJAcoQAkBwhACRHCADJNRoCLZ6SK4n+6mpzf23uTepvf00fCbT6H0L0V1eb+2tzb1If+2s6BAA0rNZkIduXSvq2Rmb+/W1E3FZaf6ZnxbGa/X/PD+qABjVryvvvNfqrp839tbk3qfv9/VJv65044LFqUw6Bqdwc5ETPjU/5ointD8DUrY912hd7xwyBOqcD3BwE+ACoEwLT4eYgADqY0esdVJc6lknSsTqu17sDMEl1jgQmdHOQiFgREcMRMdzmN2KArOqEQKtvDgJgYqZ8OhARh2xfL+mf9P83B3m2a50B6Ita7wlExBpJa7rUC4AGMGMQSI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJKr9dHkmJzdf3p+sf7UTX9drJ+z5tpy/ctPTbonoFYI2N4uab+kw5IORcRwN5oC0D/dOBL4bES80YXtAGgA7wkAydUNgZD0Y9sbbS/rRkMA+qvu6cAFEbHD9qmS1tp+LiIeG71CFQ7LJOlYHVdzdwC6rdaRQETsqL7ukfSwpEVjrLMiIoYjYnhQs+rsDkAPTDkEbM+2fcLRx5IukbSlW40B6I86pwNDkh62fXQ7P4iIf+xKV9PUjPkfLdbPv3pTsX5ER4r1n1xyR7H+lTP/qFg/9IuXi/UPuhdXfaJYv/P8Hxbrf3nXF4v1ecufnGxLrTDlEIiIn0s6r4u9AGgAlwiB5AgBIDlCAEiOEACSIwSA5AgBIDnuJ9BFb//2/GL9jo8+Umv7p8/4ULEeMwZqbX+6G/it3yzWn//cymK90zyNf7jqP4r17cuL5dbiSABIjhAAkiMEgOQIASA5QgBIjhAAkiMEgOSYJzCNXPbc4mJ9xq7X+9NIS2274cSebv9fH1xYrM/X9LyfAEcCQHKEAJAcIQAkRwgAyRECQHKEAJAcIQAkxzyBaeSln32kWD9n/yt96qQZA0OnFutLPrm+p/s/ZfM7Pd1+UzgSAJIjBIDkCAEgOUIASI4QAJIjBIDkCAEgOeYJdNFrv1cezmPqZq7rvXza+5Xy/QK+fuqPivVBlz+X4bv/fXqx/qFX9hXrh4vV9ur4XWn7Htt7bG8ZtWyu7bW2X6y+zultmwB6ZSI/mr4n6dL3LLtJ0rqIOFvSuuo5gGmoYwhExGOS9r5n8eWSVlWPV0la3N22APTLVE9ShyJiZ/V4l6ShLvUDoM9qXx2IiJAU49VtL7O9wfaGgzpQd3cAumyqIbDb9jxJqr7uGW/FiFgREcMRMTyoWVPcHYBemWoIrJa0tHq8VFK9z9wG0JiO8wRs3y/pQkkn235V0i2SbpP0gO0vSXpZ0pW9bHK6uOSiTcX6ER2pt4NxT7ogdR7fgx3G7+E/vqi8wtanJ9nR9NAxBCJiyTilDiMGYDpg2jCQHCEAJEcIAMkRAkByhACQHCEAJMf9BKaRc+98s1ifrr/PftTAh+cW62/8zim93f9/vVWsT/fxHQ9HAkByhACQHCEAJEcIAMkRAkByhACQHCEAJMc8gUk48PlPFutXn/w3tba/7Z3y78Mf3vpCre233f8sOqtYf/wb36m1/cueW1ysz9j1eq3tT1ccCQDJEQJAcoQAkBwhACRHCADJEQJAcoQAkBzzBCZh/2nl4TpvZr3tf/O1937487u9sPI3yhto+HMJTnmyPD4n/eKXxfqb1+7vZjvv89LPPlKsn7P/lZ7uv604EgCSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDnmCUyGy+VjambqqjN+UqwPnvlosX4wmr0z/uAfDBTr9fur+TOrw79fVh1H1fY9tvfY3jJq2a22d9jeXP25rLdtAuiViUTr9ySNNZXtjohYUP1Z0922APRLxxCIiMck7e1DLwAaUOck63rbT1enC3O61hGAvppqCNwl6SxJCyTtlHT7eCvaXmZ7g+0NB3VgirsD0CtTCoGI2B0RhyPiiKSVkhYV1l0REcMRMTyoWVPtE0CPTCkEbM8b9fQKSVvGWxdAu3WcJ2D7fkkXSjrZ9quSbpF0oe0FGvkN9u2Sruldi+1xwn8eKtY3djjbWTir/LkCnRzscL+AI6q3/dcOlf8Ca94+t1gf6LD/y45/vlgfGujxkWLD91toq44hEBFLxlh8dw96AdAApg0DyRECQHKEAJAcIQAkRwgAyRECQHLcT2ASZv3oqWL9xq9dV6yf95Wf1tr/C1/7eHmFqHchfOBA+Tr/zD1v1dr+3w39frF+8XceL9ZvnLu1vP23yp8rcO6dbxbrzd6NoTkcCQDJEQJAcoQAkBwhACRHCADJEQJAcoQAkBzzBLropO//e7G+/fv1tj9T5XkKvVb3OvrbCz5drH/2+PI8gE7+6v4/LNZP3/pkre1/UHEkACRHCADJEQJAcoQAkBwhACRHCADJEQJAcswTQN/8xdfvLdbPm9mnRvAuHAkAyRECQHKEAJAcIQAkRwgAyRECQHKEAJAc8wTQNwMuf67BMfxMakTHUbd9mu1HbW+1/aztG6rlc22vtf1i9XVO79sF0G0Tid5Dkr4aER+T9GlJ19n+mKSbJK2LiLMlraueA5hmOoZAROyMiE3V4/2StkmaL+lySauq1VZJWtyjHgH00KROwmyfIWmhpPWShiJiZ1XaJWmou60B6IcJh4Dt4yU9KOnGiNg3uhYRIWnMT8O0vcz2BtsbDupArWYBdN+EQsD2oEYC4L6IeKhavNv2vKo+T9KesV4bESsiYjgihgc1qxs9A+iiiVwdsKS7JW2LiOWjSqslLa0eL5X0SPfbA9BrE5kn8BlJX5D0jO3N1bKbJd0m6QHbX5L0sqQre9Ihpo3X/uz8Yv2CY/+tWD/S4dvxtUPl08mTXizPQ8DYOoZARDwhyeOUL+puOwD6jSlaQHKEAJAcIQAkRwgAyRECQHKEAJAc9xNA1xycXa4f63rfbrOPGe9K9Yh3TizXMTaOBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI55AuiaM1a/Waz/9Ory68+bWa5f8MSfFOuzZjNPYCo4EgCSIwSA5AgBIDlCAEiOEACSIwSA5AgBIDnmCaBrYuOzxfpV/3Jtsb7t4u8W6yf+83HF+odXPlmsY2wcCQDJEQJAcoQAkBwhACRHCADJEQJAcoQAkJwjoryCfZqkeyUNSQpJKyLi27ZvlfRlSa9Xq94cEWtK2zrRc+NT5tPMgX5bH+u0L/aOecOFiUwWOiTpqxGxyfYJkjbaXlvV7oiIb3WrUQD91zEEImKnpJ3V4/22t0ma3+vGAPTHpN4TsH2GpIWS1leLrrf9tO17bM/pdnMAem/CIWD7eEkPSroxIvZJukvSWZIWaORI4fZxXrfM9gbbGw7qQP2OAXTVhELA9qBGAuC+iHhIkiJid0QcjogjklZKWjTWayNiRUQMR8TwoGZ1q28AXdIxBGxb0t2StkXE8lHL541a7QpJW7rfHoBem8jVgc9I+oKkZ2xvrpbdLGmJ7QUauWy4XdI1PegPQI9N5OrAE5LGur5YnBMAYHpgxiCQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMl1/NyBru7Mfl3Sy6MWnSzpjb41MHn0V0+b+2tzb1L3+/u1iDhlrEJfQ+B9O7c3RMRwYw10QH/1tLm/Nvcm9bc/TgeA5AgBILmmQ2BFw/vvhP7qaXN/be5N6mN/jb4nAKB5TR8JAGgYIQAkRwgAyRECQHKEAJDc/wKjUuRttfAvgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIGCWjGtLzPj"
   },
   "source": [
    "### Building Neural Network Model Using hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "v-tS8rVaLqwl",
    "outputId": "b829a770-3b4c-4c15-f5c4-4dd9e7adb0a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_shape=(784,), activation='relu'))\n",
    "model2.add(Dense(100, input_shape=(100,),activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "Ff-aZb_RN0qD",
    "outputId": "cf0a7d22-5dfa-4c17-b647-19a402bb9b79"
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "Ff-aZb_RN0qD",
    "outputId": "cf0a7d22-5dfa-4c17-b647-19a402bb9b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.9022\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1410 - accuracy: 0.9583\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9698\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9762\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ca6d61a30>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model2.fit(X_train_flattened, y_train, batch_size= 128,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thtxdz9mM4hG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 898us/step - loss: 0.0874 - accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08735445886850357, 0.9735999703407288]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model2.evaluate(X_test_flattened,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57Mi2yePNGmb"
   },
   "source": [
    "**Try yourself**: \n",
    "Change the values of epochs and try adding more hidden layers. Are you able to increase the accuracy above 97.5%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 526)               412910    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               67456     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 491,032\n",
      "Trainable params: 491,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Dense(526, input_shape=(784,), activation='relu'))          #input layers with 526 neuron and input size as 784\n",
    "\n",
    "model3.add(Dense(128,activation='relu'))     #hidden layers with 128 neuron\n",
    "model3.add(Dense(64,activation='relu'))      #hidden layers with 64 neuron \n",
    "model3.add(Dense(32,activation='relu'))      #hidden layers with 32 neuron\n",
    "\n",
    "model3.add(Dense(10, activation='softmax'))    #output layers with 10 neuron \n",
    "\n",
    "model3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])    #compile moel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.2522 - accuracy: 0.9248\n",
      "Epoch 2/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0922 - accuracy: 0.9715\n",
      "Epoch 3/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0597 - accuracy: 0.9811\n",
      "Epoch 4/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0441 - accuracy: 0.9851\n",
      "Epoch 5/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0287 - accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0265 - accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "706/706 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.99 - 3s 4ms/step - loss: 0.0217 - accuracy: 0.9932\n",
      "Epoch 9/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0209 - accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "706/706 [==============================] - 3s 4ms/step - loss: 0.0150 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ca7e5c430>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train_flattened, y_train, batch_size=85,epochs=10)      #fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09445890784263611, 0.9781000018119812]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test_flattened,y_test)         #evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**by increasing number of hidden layers gives more accurate value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F91VHEpJONIF"
   },
   "source": [
    "# Summary\n",
    "*  We learned why we need to normalize and flatten the data.\n",
    "*  We observed the performance of very simple neural network with no hidden layer and that of with one hidden layer with 100 hidden neurons. The performance of later model was better than earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform atleast 10 modifications and submit a table containing changes made and outputs observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 1028)              806980    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               526848    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,499,342\n",
      "Trainable params: 1,499,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Dense(1028, input_shape=(784,), activation='relu'))  #input layer with 1028 neuron and 784 input size\n",
    "\n",
    "model4.add(Dense(512,activation='relu'))             #hidden layer with 512 neuron \n",
    "model4.add(Dense(256,activation='relu'))             #hidden layer with 256  neuron\n",
    "model4.add(Dense(128,activation='relu'))             #hidden layer with 128 neuron \n",
    "\n",
    "model4.add(Dense(10, activation='softmax'))           #output layer with 10 neuron \n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])   #compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "4000/4000 [==============================] - 42s 10ms/step - loss: 0.2151 - accuracy: 0.9359\n",
      "Epoch 2/15\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.1077 - accuracy: 0.9704\n",
      "Epoch 3/15\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.0820 - accuracy: 0.9768\n",
      "Epoch 4/15\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.0665 - accuracy: 0.9824\n",
      "Epoch 5/15\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.0554 - accuracy: 0.9844\n",
      "Epoch 6/15\n",
      "4000/4000 [==============================] - 43s 11ms/step - loss: 0.0491 - accuracy: 0.9868\n",
      "Epoch 7/15\n",
      "4000/4000 [==============================] - 43s 11ms/step - loss: 0.0435 - accuracy: 0.9886\n",
      "Epoch 8/15\n",
      "4000/4000 [==============================] - 43s 11ms/step - loss: 0.0397 - accuracy: 0.9899\n",
      "Epoch 9/15\n",
      "4000/4000 [==============================] - 46s 12ms/step - loss: 0.0389 - accuracy: 0.9903\n",
      "Epoch 10/15\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.0347 - accuracy: 0.9916\n",
      "Epoch 11/15\n",
      "4000/4000 [==============================] - 43s 11ms/step - loss: 0.0336 - accuracy: 0.9922\n",
      "Epoch 12/15\n",
      "4000/4000 [==============================] - 45s 11ms/step - loss: 0.0303 - accuracy: 0.9930\n",
      "Epoch 13/15\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.0299 - accuracy: 0.9932\n",
      "Epoch 14/15\n",
      "4000/4000 [==============================] - 44s 11ms/step - loss: 0.0324 - accuracy: 0.99350s - los\n",
      "Epoch 15/15\n",
      "4000/4000 [==============================] - 46s 11ms/step - loss: 0.0272 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ca810d580>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train_flattened, y_train, batch_size=15,epochs=15)        #fit model with epochs = 15 , batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1534 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15340788662433624, 0.9832000136375427]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test_flattened,y_test)                    #evaluate the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we observe slight variation in accuracy with silly changes in hyperparameters such as no.of epoch , batch size  and with changes in no.of hidden layers and the neuron present in it** "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JecJgLmCO5pq"
   ],
   "include_colab_link": true,
   "name": "Day 7: MNIST Multi-class classification model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
